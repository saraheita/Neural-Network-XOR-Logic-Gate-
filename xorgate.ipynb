{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOYCk9MDDvg5pQpVKkkzlev",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saraheita/Neural-Network-XOR-Logic-Gate-/blob/main/xorgate.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WqqaKASXylMQ",
        "outputId": "2d63f829-5416-4275-ea66-f8c54428c3a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 0.3462, Accuracy: 0.5000\n",
            "Epoch 1000, Loss: 0.2331, Accuracy: 0.7500\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# Define LogicGate Model\n",
        "class LogicGate(tf.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.built = False  # Track if model is initialized\n",
        "\n",
        "    def __call__(self, x, train=True):\n",
        "        # Initialize weights and bias on first call\n",
        "        if not self.built:\n",
        "            input_dim = x.shape[-1]  # Number of input features\n",
        "            self.w = tf.Variable(tf.random.normal([input_dim, 2]), name=\"weights\")  # 2 neurons\n",
        "            self.b = tf.Variable(tf.zeros([2]), name=\"bias\")\n",
        "            self.w_out = tf.Variable(tf.random.normal([2, 1]), name=\"weights_out\")  # Output layer\n",
        "            self.b_out = tf.Variable(tf.zeros([1]), name=\"bias_out\")\n",
        "            self.built = True\n",
        "\n",
        "        # Hidden layer\n",
        "        hidden = tf.sigmoid(tf.add(tf.matmul(x, self.w), self.b))\n",
        "        # Output layer\n",
        "        z = tf.sigmoid(tf.add(tf.matmul(hidden, self.w_out), self.b_out))\n",
        "        return z\n",
        "\n",
        "# Loss function (Mean Squared Error)\n",
        "def compute_loss(y_pred, y_true):\n",
        "    return tf.reduce_mean(tf.square(y_pred - y_true))\n",
        "\n",
        "# Training function\n",
        "def train_model(model, x_train, y_train, learning_rate=0.5, epochs=6000):\n",
        "    for epoch in range(epochs):\n",
        "        with tf.GradientTape() as tape:\n",
        "            y_pred = model(x_train)  # Forward pass\n",
        "            loss = compute_loss(y_pred, y_train)\n",
        "\n",
        "        # Update the parameters with respect to the gradient calculations\n",
        "        grads = tape.gradient(loss, model.variables)\n",
        "        for g, v in zip(grads, model.variables):\n",
        "            v.assign_sub(learning_rate * g)\n",
        "\n",
        "        # Print progress every 1000 epochs\n",
        "        if epoch % 1000 == 0:\n",
        "            acc = compute_accuracy(model, x_train, y_train)\n",
        "            print(f\"Epoch {epoch}, Loss: {loss.numpy():.4f}, Accuracy: {acc:.4f}\")\n",
        "\n",
        "# Accuracy function\n",
        "def compute_accuracy(model, x, y_true):\n",
        "    y_pred = model(x, train=False)\n",
        "    y_pred_rounded = tf.round(y_pred)\n",
        "    correct = tf.equal(y_pred_rounded, y_true)\n",
        "    return tf.reduce_mean(tf.cast(correct, tf.float32)).numpy()\n",
        "\n",
        "# Prepare XOR gate dataset\n",
        "xor_table = np.array([[0, 0, 0],\n",
        "                      [0, 1, 1],\n",
        "                      [1, 0, 1],\n",
        "                      [1, 1, 0]], dtype=np.float32)\n",
        "\n",
        "x_train = xor_table[:, :2]  # Inputs: x1, x2\n",
        "y_train = xor_table[:, 2:]  # Labels: y\n",
        "\n",
        "# Initialize and train model\n",
        "model = LogicGate()\n",
        "train_model(model, x_train, y_train)\n",
        "\n",
        "# Evaluate and print results\n",
        "print(\"\\nLearned Parameters:\")\n",
        "print(\"Weights (input to hidden):\", model.w.numpy())\n",
        "print(\"Biases (hidden):\", model.b.numpy())\n",
        "print(\"Weights (hidden to output):\", model.w_out.numpy())\n",
        "print(\"Bias (output):\", model.b_out.numpy())\n",
        "\n",
        "# Test model predictions\n",
        "y_pred = model(x_train, train=False).numpy().round().astype(np.uint8)\n",
        "print(\"\\nPredicted XOR Truth Table:\")\n",
        "print(np.column_stack((xor_table[:, :2], y_pred)))\n"
      ]
    }
  ]
}